---
title: Jailbreaking
layout: article.njk
image: /assets/uploads/adobestock_351071184-large.jpeg
intro: null
blocks: []
---
AI-jailbreaking er vores eksperimenterende tilgang til kompetenceudvikling i arbejdet med generativ AI. Ved bevidst at udfordre systemernes indbyggede grænser og sikkerhedsforanstaltninger undersøger vi, hvordan kreative “forstyrrelser” kan give dybere indsigt i, hvordan AI faktisk fungerer, hvor dens svagheder ligger, og hvilke risici der opstår, når teknologien anvendes ukritisk.

I stedet for at se jailbreaking som et forsøg på at omgå regler, bruger vi det som en pædagogisk metode: Deltagere lærer at stille bedre spørgsmål, vurdere output kritisk og forstå, hvordan modeller kan manipuleres eller misforstå kontekst. Formålet er at undersøge om denne form for hands-on udforskning styrker professionelle kompetencer inden for ansvarlig brug af AI — særligt dømmekraft, risikoforståelse og evnen til at identificere bias, sårbarheder og utilsigtede effekter.

<img src="/assets/uploads/jailbreak.jpeg" alt="" class="img-center img-full img-h-200 img-fade-all img-rounded">
